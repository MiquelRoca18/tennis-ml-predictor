# üéæ Tennis ML Predictor

Sistema de predicci√≥n de partidos de tenis usando Machine Learning con probabilidades calibradas para apuestas deportivas.

## üìä Resultados Actuales (Fase 2 Completada)

- **Accuracy**: 69.82% en test set 2025
- **Brier Score**: 0.1991 (calibraci√≥n excelente)
- **ECE**: 0.0222 (calibraci√≥n casi perfecta)
- **ROI en Backtesting**: 57.41% (excepcional)
- **Modelo**: Random Forest con 30 features seleccionadas

---

## üöÄ Inicio R√°pido

### Requisitos Previos

- Python 3.8+
- pip
- Git

### Instalaci√≥n

```bash
# 1. Clonar el repositorio
git clone https://github.com/TU_USUARIO/tennis-ml-predictor.git
cd tennis-ml-predictor

# 2. Crear entorno virtual
python -m venv venv
source venv/bin/activate  # En Windows: venv\Scripts\activate

# 3. Instalar dependencias
pip install -r requirements.txt

# 4. Crear estructura de carpetas
mkdir -p datos/raw datos/processed datos/tml_database
mkdir -p modelos resultados/calibracion resultados/backtesting logs
```

---

## üìã Pipeline Completo - Paso a Paso

### **Paso 1: Descargar Datos** üì•

Descarga datos hist√≥ricos de partidos de tenis desde TML Database (2022-2025):

```bash
python src/data/tml_data_downloader.py
```

**Salida esperada**:
- `datos/tml_database/tml_tennis.db` - Base de datos SQLite con ~25,000 partidos
- Tiempo estimado: 2-3 minutos

---

### **Paso 2: Procesar Datos** üîÑ

Procesa los datos raw y crea el dataset base:

```bash
python src/data/data_processor.py
```

**Salida esperada**:
- `datos/processed/dataset_base.csv` - Dataset con features b√°sicas
- Tiempo estimado: 1 minuto

---

### **Paso 3: Feature Engineering** üõ†Ô∏è

Genera las 149 features avanzadas (ELO, servicio, fatiga, forma reciente, etc.):

```bash
python run_feature_engineering_fase3.py
```

**Salida esperada**:
- `datos/processed/dataset_features_fase3_completas.csv` - Dataset con 149 features
- Tiempo estimado: 3-5 minutos

**Features generadas**:
- Sistema ELO (general y por superficie)
- Estad√≠sticas de servicio y resto
- M√©tricas de fatiga
- Forma reciente (30, 60, 90 d√≠as)
- Head-to-Head hist√≥rico
- Especializaci√≥n por superficie

---

### **Paso 4: Entrenamiento y Optimizaci√≥n** ü§ñ

Entrena m√∫ltiples modelos, selecciona features y optimiza hiperpar√°metros:

```bash
python run_fase3_optimization.py
```

**Salida esperada**:
- `modelos/random_forest_calibrado.pkl` - Modelo Random Forest calibrado
- `modelos/xgboost_calibrado.pkl` - Modelo XGBoost calibrado
- `modelos/gradient_boosting_calibrado.pkl` - Modelo Gradient Boosting calibrado
- `modelos/logistic_regression_calibrado.pkl` - Modelo Logistic Regression calibrado
- `resultados/selected_features.txt` - 30 features seleccionadas
- `resultados/model_comparison.png` - Comparaci√≥n de modelos
- `resultados/hyperparameter_tuning_results.csv` - Resultados de tuning
- Tiempo estimado: 10-15 minutos

**Proceso incluye**:
1. Entrenamiento de 4 modelos base
2. Selecci√≥n de 30 mejores features
3. Re-entrenamiento con features seleccionadas
4. Calibraci√≥n con Isotonic Regression
5. Comparaci√≥n y selecci√≥n del mejor modelo

---

### **Paso 5: Validaci√≥n de Calibraci√≥n** üéØ

Valida que las probabilidades del modelo sean confiables:

```bash
python validacion_calibracion.py
```

**Salida esperada**:
- `resultados/calibracion/calibration_metrics.csv` - M√©tricas de calibraci√≥n
- `resultados/calibracion/calibration_comparison_all_models.png` - Comparaci√≥n visual
- `resultados/calibracion/reliability_diagrams/` - Diagramas individuales por modelo
- Tiempo estimado: 2 minutos

**M√©tricas validadas**:
- Brier Score < 0.20 ‚úÖ
- ECE < 0.05 ‚úÖ
- Reliability diagrams ‚úÖ

---

### **Paso 6: Backtesting** üé≤

Simula apuestas en datos hist√≥ricos para validar rentabilidad:

```bash
python backtesting_fase2.py
```

**Salida esperada**:
- `resultados/backtesting/ev_threshold_comparison.csv` - Comparaci√≥n de umbrales
- `resultados/backtesting/cumulative_profit_ev*.png` - Curvas de ganancias
- `resultados/backtesting/all_bets_detailed.csv` - Detalle de todas las apuestas
- Tiempo estimado: 5 minutos

**An√°lisis incluye**:
- 4 umbrales de EV (0%, 3%, 5%, 8%)
- ROI, Win Rate, Profit Factor
- An√°lisis de drawdown
- An√°lisis por superficie y rangos de EV

---

### **Paso 7: Reporte Final** üìä

Genera reporte HTML interactivo con todos los resultados:

```bash
python generar_reporte_fase2.py
```

**Salida esperada**:
- `resultados/REPORTE_FASE_2.html` - Reporte interactivo completo
- Tiempo estimado: 30 segundos

---

## ‚ö° Pipeline Completo Automatizado

Si quieres ejecutar todo el proceso de una vez:

```bash
# Ejecuta Fase 2 completa (validaci√≥n + backtesting + reporte)
python run_fase2_completa.py
```

**Nota**: Aseg√∫rate de haber ejecutado los pasos 1-4 primero.

---

## üìÅ Estructura del Proyecto

```
tennis-ml-predictor/
‚îú‚îÄ‚îÄ datos/
‚îÇ   ‚îú‚îÄ‚îÄ raw/                    # Datos crudos (ignorados en Git)
‚îÇ   ‚îú‚îÄ‚îÄ processed/              # Datasets procesados (ignorados en Git)
‚îÇ   ‚îî‚îÄ‚îÄ tml_database/           # Base de datos TML (ignorada en Git)
‚îÇ
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ tml_data_downloader.py    # Descarga datos de TML
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ data_processor.py         # Procesa datos raw
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ features/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ feature_engineer_completo.py  # Feature engineering completo
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ elo_rating_system.py          # Sistema ELO
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ features_servicio_resto.py    # Stats servicio/resto
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ features_fatiga.py            # M√©tricas de fatiga
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ features_forma_reciente.py    # Forma reciente
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ features_h2h_mejorado.py      # Head-to-Head
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ features_superficie.py        # Especializaci√≥n superficie
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ models/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ comparacion_modelos.py        # Comparaci√≥n de modelos
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ feature_selection.py          # Selecci√≥n de features
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ hyperparameter_tuning.py      # Optimizaci√≥n hiperpar√°metros
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ weighted_ensemble.py          # Ensemble de modelos
‚îÇ   ‚îÇ
‚îÇ   ‚îî‚îÄ‚îÄ utils/
‚îÇ       ‚îî‚îÄ‚îÄ __init__.py
‚îÇ
‚îú‚îÄ‚îÄ modelos/                    # Modelos entrenados (ignorados en Git)
‚îÇ   ‚îú‚îÄ‚îÄ random_forest_calibrado.pkl
‚îÇ   ‚îú‚îÄ‚îÄ xgboost_calibrado.pkl
‚îÇ   ‚îú‚îÄ‚îÄ gradient_boosting_calibrado.pkl
‚îÇ   ‚îî‚îÄ‚îÄ logistic_regression_calibrado.pkl
‚îÇ
‚îú‚îÄ‚îÄ resultados/                 # Resultados y gr√°ficos (ignorados en Git)
‚îÇ   ‚îú‚îÄ‚îÄ calibracion/
‚îÇ   ‚îú‚îÄ‚îÄ backtesting/
‚îÇ   ‚îî‚îÄ‚îÄ REPORTE_FASE_2.html
‚îÇ
‚îú‚îÄ‚îÄ guiasProyecto/              # Gu√≠as de desarrollo
‚îÇ   ‚îú‚îÄ‚îÄ FASE_2_CALIBRACION.md
‚îÇ   ‚îú‚îÄ‚îÄ FASE_3_OPTIMIZACION.md
‚îÇ   ‚îî‚îÄ‚îÄ FASE_4_TRACKING.md
‚îÇ
‚îú‚îÄ‚îÄ logs/                       # Logs de ejecuci√≥n (ignorados en Git)
‚îÇ
‚îú‚îÄ‚îÄ run_feature_engineering_fase3.py  # Script feature engineering
‚îú‚îÄ‚îÄ run_fase3_optimization.py         # Script optimizaci√≥n
‚îú‚îÄ‚îÄ validacion_calibracion.py         # Script validaci√≥n
‚îú‚îÄ‚îÄ backtesting_fase2.py              # Script backtesting
‚îú‚îÄ‚îÄ generar_reporte_fase2.py          # Script reporte
‚îú‚îÄ‚îÄ run_fase2_completa.py             # Script pipeline completo
‚îú‚îÄ‚îÄ predictor_calibrado.py            # Clase predictor
‚îÇ
‚îú‚îÄ‚îÄ requirements.txt            # Dependencias Python
‚îú‚îÄ‚îÄ .gitignore                  # Archivos ignorados por Git
‚îú‚îÄ‚îÄ README.md                   # Este archivo
‚îî‚îÄ‚îÄ FASE_2_RESULTADOS.md        # Documentaci√≥n de resultados
```

---

## üéØ Uso del Modelo para Predicciones

### Predicci√≥n Simple

```python
from predictor_calibrado import PredictorCalibrado
import numpy as np

# Cargar modelo
predictor = PredictorCalibrado("modelos/random_forest_calibrado.pkl")

# Preparar features (ejemplo con las 30 features seleccionadas)
features = np.array([...])  # Tus 30 features

# Predecir
resultado = predictor.predecir(features)
print(f"Probabilidad: {resultado['probabilidad']*100:.1f}%")
print(f"Predicci√≥n: {'Gana' if resultado['prediccion'] == 1 else 'Pierde'}")
```

### An√°lisis de Apuesta

```python
# Analizar si vale la pena apostar
cuota = 2.50  # Cuota disponible
analisis = predictor.recomendar_apuesta(features, cuota, umbral_ev=0.08)

print(f"Decisi√≥n: {analisis['decision']}")
print(f"EV: {analisis['ev_porcentaje']:+.2f}%")
print(f"Ganancia esperada: {analisis['ganancia_esperada']:+.2f}‚Ç¨")
```

---

## üìä M√©tricas del Modelo

### Calibraci√≥n
- **Brier Score**: 0.1991 (< 0.20 ‚úÖ)
- **ECE**: 0.0222 (< 0.05 ‚úÖ)
- **Log Loss**: 0.5905
- **Accuracy**: 69.82%

### Backtesting (Umbral EV 8%)
- **ROI**: 57.41%
- **Win Rate**: 50.78%
- **Profit Factor**: 2.17
- **Max Drawdown**: -1.07%
- **Apuestas analizadas**: 1,030
- **Ganancia simulada**: +5,913‚Ç¨

---

## üîß Configuraci√≥n Avanzada

### Cambiar Umbral de EV

Edita el umbral en `backtesting_fase2.py`:

```python
# L√≠nea ~497
umbrales = [0.00, 0.03, 0.05, 0.08, 0.10]  # A√±ade m√°s umbrales
```

### Usar Otro Modelo

Cambia el modelo en `backtesting_fase2.py`:

```python
# L√≠nea ~689
modelo_path = "modelos/xgboost_calibrado.pkl"  # En lugar de random_forest
```

---

## üìö Documentaci√≥n Adicional

- **[FASE_2_RESULTADOS.md](FASE_2_RESULTADOS.md)** - Resultados detallados de Fase 2
- **[guiasProyecto/FASE_2_CALIBRACION.md](guiasProyecto/FASE_2_CALIBRACION.md)** - Gu√≠a de calibraci√≥n
- **[guiasProyecto/FASE_3_OPTIMIZACION.md](guiasProyecto/FASE_3_OPTIMIZACION.md)** - Gu√≠a de optimizaci√≥n
- **[guiasProyecto/FASE_4_TRACKING.md](guiasProyecto/FASE_4_TRACKING.md)** - Gu√≠a de tracking

---

## üêõ Troubleshooting

### Error: "No such file or directory: datos/..."

**Soluci√≥n**: Ejecuta los pasos en orden. Primero descarga datos (Paso 1), luego procesa (Paso 2), etc.

### Error: "X has 149 features, but model expects 30"

**Soluci√≥n**: Aseg√∫rate de usar las features seleccionadas. Carga `resultados/selected_features.txt` para ver cu√°les son.

### Error: "ModuleNotFoundError"

**Soluci√≥n**: Instala dependencias:
```bash
pip install -r requirements.txt
```

### Modelos muy lentos

**Soluci√≥n**: Reduce el tama√±o del dataset o usa menos iteraciones en hyperparameter tuning.

---

## üöÄ Pr√≥ximos Pasos (Fase 3)

- [ ] Optimizaci√≥n adicional de hiperpar√°metros
- [ ] Ensemble methods avanzados
- [ ] Feature engineering adicional
- [ ] Objetivo: Accuracy > 70%, Brier < 0.18

---

## üìù Licencia

Este proyecto es de c√≥digo abierto bajo licencia MIT.

---

## üë• Contribuciones

Las contribuciones son bienvenidas. Por favor:

1. Fork el proyecto
2. Crea una rama para tu feature (`git checkout -b feature/AmazingFeature`)
3. Commit tus cambios (`git commit -m 'Add some AmazingFeature'`)
4. Push a la rama (`git push origin feature/AmazingFeature`)
5. Abre un Pull Request

---

## üìß Contacto

Para preguntas o sugerencias, abre un issue en GitHub.

---

**√öltima actualizaci√≥n**: Diciembre 2025  
**Versi√≥n**: 2.0 (Fase 2 Completada)
