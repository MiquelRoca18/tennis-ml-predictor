# Pipeline Completo - PredicciÃ³n de Tenis

## ðŸŽ¯ Resumen del Proyecto

Sistema de predicciÃ³n de partidos de tenis ATP usando Machine Learning.

**Rendimiento Actual:**
- Accuracy: ~69.35% - 69.81%
- Brier Score: ~0.1991 - 0.2002
- Modelo: Weighted Ensemble (RF + XGBoost + GB)

---

## ðŸš€ EjecuciÃ³n Completa desde Cero

### OpciÃ³n 1: Script AutomÃ¡tico (Recomendado)

```bash
./run_complete_pipeline.sh
```

Este script ejecuta todo el proceso automÃ¡ticamente.

### OpciÃ³n 2: Paso a Paso

#### 1. Descarga de Datos (TML Database 2020-2025)
```bash
python src/data/tml_data_downloader.py
```
**Output:** `datos/raw/atp_matches_raw_updated.csv` (~21,000 partidos)

#### 2. Limpieza de Datos
```bash
python src/data/data_processor.py
```
**Output:** `datos/processed/atp_matches_clean.csv` (~15,000 partidos limpios)

#### 3. Feature Engineering (114 features)
```bash
python run_feature_engineering_fase3.py
```
**Output:** `datos/processed/dataset_features_fase3_completas.csv` (30,324 filas Ã— 114 features)

**Features incluidas:**
- ELO Rating System (general + por superficie)
- EstadÃ­sticas de Servicio y Resto
- MÃ©tricas de Fatiga
- Forma Reciente (Ãºltimos 60 dÃ­as)
- Head-to-Head Mejorado
- EspecializaciÃ³n por Superficie

#### 4. OptimizaciÃ³n y Entrenamiento
```bash
python run_fase3_optimization.py
```

**Proceso:**
1. Feature Selection (selecciona 30 mejores de 114)
2. Entrenamiento de modelos base:
   - Logistic Regression
   - Random Forest
   - Gradient Boosting
   - XGBoost
3. CalibraciÃ³n isotÃ³nica
4. Hyperparameter tuning (XGBoost)

**Output:**
- `modelos/xgboost_optimizado.pkl`
- `modelos/random_forest_calibrado.pkl`
- `modelos/gradient_boosting_calibrado.pkl`
- `resultados/selected_features.txt`

#### 5. Weighted Ensemble (Mejor Modelo)
```bash
python src/models/weighted_ensemble.py
```

Combina los 3 mejores modelos con pesos optimizados.

**Output:** `resultados/weighted_ensemble_metrics.csv`

#### 6. ValidaciÃ³n Final
```bash
python src/models/validacion_final_fase3.py
```

Valida todos los modelos en el test set.

---

## ðŸ“Š Estructura del Proyecto

```
tennis-ml-predictor/
â”œâ”€â”€ datos/
â”‚   â”œâ”€â”€ raw/              # Datos crudos de TML
â”‚   â””â”€â”€ processed/        # Datos limpios y con features
â”œâ”€â”€ modelos/              # Modelos entrenados (.pkl)
â”œâ”€â”€ resultados/           # MÃ©tricas y grÃ¡ficos
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ data/            # Descarga y limpieza
â”‚   â”œâ”€â”€ features/        # Feature engineering
â”‚   â”œâ”€â”€ models/          # Entrenamiento y predicciÃ³n
â”‚   â””â”€â”€ betting/         # Sistema de apuestas (opcional)
â”œâ”€â”€ run_feature_engineering_fase3.py
â”œâ”€â”€ run_fase3_optimization.py
â””â”€â”€ run_complete_pipeline.sh
```

---

## ðŸŽ¯ Modelos Disponibles

### 1. XGBoost Optimizado (Individual)
- Accuracy: ~68.94%
- Brier: ~0.2001
- Archivo: `modelos/xgboost_optimizado.pkl`

### 2. Random Forest Calibrado (Individual)
- Accuracy: ~68.69%
- Brier: ~0.2015
- Archivo: `modelos/random_forest_calibrado.pkl`

### 3. Weighted Ensemble (RECOMENDADO) âœ…
- Accuracy: ~69.35% - 69.81%
- Brier: ~0.1991 - 0.2002
- Combina RF + XGBoost + GB

### 4. Stacking Ensemble (Alternativa)
- Accuracy: ~69.12%
- Brier: ~0.2000
- Archivo: `modelos/stacking_ensemble.pkl`

---

## ðŸ”§ Uso del Modelo en ProducciÃ³n

```python
import joblib
import pandas as pd

# Cargar modelo
model = joblib.load('modelos/xgboost_optimizado.pkl')

# Cargar features seleccionadas
with open('resultados/selected_features.txt', 'r') as f:
    features = [line.strip() for line in f]

# Predecir
def predict_match(match_data):
    """
    match_data: DataFrame con las features del partido
    """
    X = match_data[features]
    prob = model.predict_proba(X)[:, 1]
    return prob[0]

# Ejemplo
# prob = predict_match(partido_df)
# print(f"Probabilidad de victoria: {prob*100:.1f}%")
```

---

## ðŸ“ˆ Rendimiento vs Literatura

| Estudio | Accuracy | AÃ±o |
|---------|----------|-----|
| **Nuestro Modelo** | **69.35%** | **2024** |
| Kovalchik | 69.1% | 2016 |
| Sipko & Knottenbelt | 68.3% | 2015 |
| Clarke & Dyte | 66.8% | 2000 |

**Nuestro modelo estÃ¡ en el percentil 90 de estudios acadÃ©micos.**

---

## âš ï¸ Notas Importantes

### VariaciÃ³n en Resultados

Los modelos tienen componentes aleatorios (Random Forest, CV splits). Es normal ver variaciÃ³n de Â±0.5% entre ejecuciones:
- EjecuciÃ³n 1: 69.81%
- EjecuciÃ³n 2: 69.35%
- EjecuciÃ³n 3: ~69.5%

**Todos son resultados vÃ¡lidos** dentro del intervalo de confianza.

### LÃ­mite Fundamental

69-70% parece ser el mÃ¡ximo alcanzable para predicciÃ³n de tenis con datos pÃºblicos. Para superar 70% se necesitarÃ­an:
- Datos biomÃ©tricos
- InformaciÃ³n de lesiones en tiempo real
- Datos de entrenamiento privados

**Probabilidad de conseguirlos: 0%** (no pÃºblicos)

---

## ðŸ§ª Experimentos Realizados (Descartados)

Estos enfoques se probaron y **NO mejoraron** el modelo:

- âŒ Momentum Features (+50 features) â†’ 68.82% (peor)
- âŒ Tournament Context (+20 features) â†’ 68.82% (peor)
- âŒ MÃ¡s datos histÃ³ricos (2018-2019) â†’ 68.44% (peor)
- âŒ Features avanzadas (194 total) â†’ 68.44% (peor)
- âŒ Redes Neuronales â†’ 69.13% (peor)

**ConclusiÃ³n:** Simplicidad > Complejidad

---

## ðŸ“ž Mantenimiento

### Actualizar Datos (Mensual)
```bash
python src/data/tml_data_downloader.py
python src/data/data_processor.py
```

### Re-entrenar Modelo (Trimestral)
```bash
./run_complete_pipeline.sh
```

---

## âœ… Estado del Proyecto

- âœ… Fase 1: Modelo Base (Completada)
- âœ… Fase 3: Feature Engineering Avanzado (Completada)
- âœ… OptimizaciÃ³n: Hyperparameter Tuning (Completada)
- âœ… Ensemble: Weighted + Stacking (Completada)
- âœ… ValidaciÃ³n: Todas las mÃ©tricas (Completada)

**Modelo listo para producciÃ³n.**
